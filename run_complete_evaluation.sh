#!/bin/bash
################################################################################
# SCRIPT MAESTRO DE EVALUACIÃ“N COMPLETA PARA TESIS
################################################################################
# 
# Este script ejecuta una evaluaciÃ³n completa de todas las arquitecturas
# agentivas con y sin perturbaciones, mÃºltiples contextos, y genera reportes
# automÃ¡ticos listos para incluir en la tesis.
#
# Autor: Benchmark Social Robot
# Fecha: 2025-01-18
################################################################################

set -e

# ============================================================================
# CONFIGURACIÃ“N GENERAL
# ============================================================================

# Modelos y providers
PROVIDER="azure"
MODEL="gpt-4o-mini"

# Arquitecturas a evaluar
ARCHITECTURES=("react" "plan-then-act" "reference" "reflexion")

# Suites de tareas
TASK_SUITE="complex"  # complex tiene mÃ¡s variedad para robustez

# ConfiguraciÃ³n de robustez
NUM_CONTEXTS=5  # NÃºmero de contextos por arquitectura (5 = rÃ¡pido, 10 = riguroso)

# ConfiguraciÃ³n de ejecuciÃ³n
MAX_ITERATIONS=15
TIMEOUT=3600  # 30 minutos por arquitectura/contexto (48 tareas complejas)

# Directorio de resultados
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
RESULTS_BASE="tesis_results_${TIMESTAMP}"
mkdir -p "$RESULTS_BASE"

# Colores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# ============================================================================
# FUNCIONES DE UTILIDAD
# ============================================================================

log_section() {
    echo ""
    echo -e "${MAGENTA}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${MAGENTA}$1${NC}"
    echo -e "${MAGENTA}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo ""
}

log_info() {
    echo -e "${BLUE}â„¹ï¸  $1${NC}"
}

log_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

log_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

log_error() {
    echo -e "${RED}âŒ $1${NC}"
}

log_progress() {
    echo -e "${CYAN}ğŸ”„ $1${NC}"
}

# ============================================================================
# BANNER INICIAL
# ============================================================================

clear
echo -e "${MAGENTA}"
cat << "EOF"
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘              EVALUACIÃ“N COMPLETA DE ARQUITECTURAS AGENTIVAS                  â•‘
â•‘                   Benchmark para Tesis de Grado                              â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EOF
echo -e "${NC}"

log_info "Directorio de resultados: $RESULTS_BASE"
log_info "Arquitecturas: ${ARCHITECTURES[*]}"
log_info "Contextos por arquitectura: $NUM_CONTEXTS"
log_info "Provider: $PROVIDER"
log_info "Modelo: $MODEL"
echo ""

# Confirmar antes de continuar
read -p "Â¿Desea continuar con la evaluaciÃ³n completa? (s/n): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[SsYy]$ ]]; then
    log_warning "EvaluaciÃ³n cancelada por el usuario"
    exit 0
fi

# Activar entorno virtual
log_progress "Activando entorno virtual..."
source ~/venvs/llm311/bin/activate
log_success "Entorno activado"

# ============================================================================
# FASE 1: BASELINE SIN PERTURBACIONES
# ============================================================================

log_section "FASE 1: EVALUACIÃ“N BASELINE (SIN PERTURBACIONES)"

BASELINE_DIR="$RESULTS_BASE/baseline"
mkdir -p "$BASELINE_DIR"

for arch in "${ARCHITECTURES[@]}"; do
    log_progress "Evaluando $arch (Baseline)..."
    
    for context in $(seq 1 $NUM_CONTEXTS); do
        log_info "  Contexto $context/$NUM_CONTEXTS"
        
        OUTPUT_FILE="${BASELINE_DIR}/${arch}_context${context}.json"
        
        timeout $TIMEOUT python run_benchmark.py \
            -a "$arch" \
            -p "$PROVIDER" \
            -m "$MODEL" \
            --task-suite "$TASK_SUITE" \
            --max-iterations "$MAX_ITERATIONS" \
            --context-seed "$context" \
            2>&1 | tee "${BASELINE_DIR}/${arch}_context${context}.log" > /dev/null
        
        # Mover resultado (buscar archivo mÃ¡s reciente que coincida con el patrÃ³n)
        # El modelo puede reportarse como "unknown" asÃ­ que buscamos por arquitectura y task_suite
        if [ "$TASK_SUITE" = "simple" ]; then
            PATTERN="benchmark_results/benchmark_${arch}_*.json"
        else
            PATTERN="benchmark_results/benchmark_${arch}_*_${TASK_SUITE}.json"
        fi
        
        # Buscar el archivo mÃ¡s reciente que coincida
        RESULT_FILE=$(ls -t $PATTERN 2>/dev/null | head -1)
        
        if [ -n "$RESULT_FILE" ] && [ -f "$RESULT_FILE" ]; then
            mv "$RESULT_FILE" "$OUTPUT_FILE"
            log_success "    âœ“ Guardado en $OUTPUT_FILE"
        else
            log_error "    âœ— No se generÃ³ resultado (patrÃ³n buscado: $PATTERN)"
        fi
        
        sleep 2
    done
    
    log_success "$arch baseline completado"
    echo ""
done

log_success "FASE 1 COMPLETADA"

# ============================================================================
# FASE 2: EVALUACIÃ“N CON PERTURBACIONES
# ============================================================================

log_section "FASE 2: EVALUACIÃ“N CON PERTURBACIONES"

PERTURBED_DIR="$RESULTS_BASE/perturbed"
mkdir -p "$PERTURBED_DIR"

# Tipos de perturbaciones a probar
PERTURBATION_TYPES="distractors noise"

for arch in "${ARCHITECTURES[@]}"; do
    log_progress "Evaluando $arch (Con Perturbaciones)..."
    
    for context in $(seq 1 $NUM_CONTEXTS); do
        log_info "  Contexto $context/$NUM_CONTEXTS"
        
        OUTPUT_FILE="${PERTURBED_DIR}/${arch}_context${context}.json"
        
        timeout $TIMEOUT python run_benchmark.py \
            -a "$arch" \
            -p "$PROVIDER" \
            -m "$MODEL" \
            --task-suite "$TASK_SUITE" \
            --max-iterations "$MAX_ITERATIONS" \
            --context-seed "$context" \
            --perturbations \
            --perturbation-types $PERTURBATION_TYPES \
            2>&1 | tee "${PERTURBED_DIR}/${arch}_context${context}.log" > /dev/null
        
        # Mover resultado (buscar archivo mÃ¡s reciente que coincida con el patrÃ³n)
        # El modelo puede reportarse como "unknown" asÃ­ que buscamos por arquitectura y task_suite
        if [ "$TASK_SUITE" = "simple" ]; then
            PATTERN="benchmark_results/benchmark_${arch}_*.json"
        else
            PATTERN="benchmark_results/benchmark_${arch}_*_${TASK_SUITE}.json"
        fi
        
        # Buscar el archivo mÃ¡s reciente que coincida
        RESULT_FILE=$(ls -t $PATTERN 2>/dev/null | head -1)
        
        if [ -n "$RESULT_FILE" ] && [ -f "$RESULT_FILE" ]; then
            mv "$RESULT_FILE" "$OUTPUT_FILE"
            log_success "    âœ“ Guardado en $OUTPUT_FILE"
        else
            log_error "    âœ— No se generÃ³ resultado (patrÃ³n buscado: $PATTERN)"
        fi
        
        sleep 2
    done
    
    log_success "$arch con perturbaciones completado"
    echo ""
done

log_success "FASE 2 COMPLETADA"

# ============================================================================
# FASE 3: ANÃLISIS Y GENERACIÃ“N DE REPORTES
# ============================================================================

log_section "FASE 3: GENERACIÃ“N DE REPORTES Y ANÃLISIS"

REPORTS_DIR="$RESULTS_BASE/reports"
mkdir -p "$REPORTS_DIR"

log_progress "Generando anÃ¡lisis de robustez para cada arquitectura..."

# AnÃ¡lisis de robustez para baseline
for arch in "${ARCHITECTURES[@]}"; do
    log_info "  Analizando robustez de $arch (Baseline)..."
    
    python analyze_robustness.py \
        "${BASELINE_DIR}/${arch}_context"*.json \
        > "${REPORTS_DIR}/robustez_${arch}_baseline.txt"
    
    log_success "    âœ“ Reporte guardado"
done

# AnÃ¡lisis de robustez con perturbaciones
for arch in "${ARCHITECTURES[@]}"; do
    log_info "  Analizando robustez de $arch (Con Perturbaciones)..."
    
    python analyze_robustness.py \
        "${PERTURBED_DIR}/${arch}_context"*.json \
        > "${REPORTS_DIR}/robustez_${arch}_perturbed.txt"
    
    log_success "    âœ“ Reporte guardado"
done

log_success "AnÃ¡lisis de robustez completado"
echo ""

# ============================================================================
# FASE 4: GENERACIÃ“N DE DATOS PARA GRÃFICOS Y TABLAS
# ============================================================================

log_section "FASE 4: GENERACIÃ“N DE DATOS PARA GRÃFICOS"

log_progress "Generando CSV para grÃ¡ficos y tablas..."

# Crear script Python para generar CSVs
cat > "${REPORTS_DIR}/generate_csv_data.py" << 'EOFPYTHON'
import json
import csv
import sys
from pathlib import Path
import statistics

def load_json(file_path):
    with open(file_path, 'r') as f:
        return json.load(f)

def extract_metrics(results_data):
    """Extrae mÃ©tricas de un archivo de resultados."""
    results = results_data.get("results", [])
    metadata = results_data.get("metadata", {})
    
    if not results:
        return None
    
    total = len(results)
    success = sum(1 for r in results if r.get("success", False))
    
    times = [r.get("execution_time", 0) for r in results]
    steps = [r.get("steps", 0) for r in results]
    tokens = [r.get("metrics", {}).get("total_tokens", 0) for r in results]
    
    return {
        "architecture": metadata.get("architecture", "unknown"),
        "success_rate": (success / total * 100) if total > 0 else 0,
        "avg_time": sum(times) / total if total > 0 else 0,
        "avg_steps": sum(steps) / total if total > 0 else 0,
        "avg_tokens": sum(tokens) / total if total > 0 else 0
    }

def generate_comparison_csv(baseline_dir, perturbed_dir, output_file):
    """Genera CSV con comparaciÃ³n de todas las arquitecturas."""
    
    # Recopilar datos
    data = []
    
    for condition, directory in [("Baseline", baseline_dir), ("Perturbado", perturbed_dir)]:
        for json_file in Path(directory).glob("*.json"):
            metrics = extract_metrics(load_json(json_file))
            if metrics:
                metrics["condition"] = condition
                metrics["context"] = json_file.stem.split("_")[-1]
                data.append(metrics)
    
    # Escribir CSV
    if data:
        fieldnames = ["architecture", "condition", "context", "success_rate", 
                     "avg_time", "avg_steps", "avg_tokens"]
        
        with open(output_file, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(data)
        
        print(f"âœ… CSV generado: {output_file}")
    else:
        print("âŒ No se encontraron datos")

def generate_summary_table(baseline_dir, perturbed_dir, output_file):
    """Genera tabla resumen con estadÃ­sticas agregadas."""
    
    summary = {}
    
    for condition, directory in [("Baseline", baseline_dir), ("Perturbado", perturbed_dir)]:
        for arch in ["react", "plan-then-act", "reference", "reflexion"]:
            files = list(Path(directory).glob(f"{arch}_context*.json"))
            
            if not files:
                continue
            
            all_metrics = [extract_metrics(load_json(f)) for f in files]
            all_metrics = [m for m in all_metrics if m]
            
            if not all_metrics:
                continue
            
            key = f"{arch}_{condition}"
            
            success_rates = [m["success_rate"] for m in all_metrics]
            times = [m["avg_time"] for m in all_metrics]
            steps = [m["avg_steps"] for m in all_metrics]
            tokens = [m["avg_tokens"] for m in all_metrics]
            
            summary[key] = {
                "architecture": arch,
                "condition": condition,
                "success_mean": statistics.mean(success_rates),
                "success_std": statistics.stdev(success_rates) if len(success_rates) > 1 else 0,
                "time_mean": statistics.mean(times),
                "time_std": statistics.stdev(times) if len(times) > 1 else 0,
                "steps_mean": statistics.mean(steps),
                "steps_std": statistics.stdev(steps) if len(steps) > 1 else 0,
                "tokens_mean": statistics.mean(tokens),
                "tokens_std": statistics.stdev(tokens) if len(tokens) > 1 else 0
            }
    
    # Escribir CSV
    if summary:
        fieldnames = ["architecture", "condition", "success_mean", "success_std",
                     "time_mean", "time_std", "steps_mean", "steps_std",
                     "tokens_mean", "tokens_std"]
        
        with open(output_file, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(summary.values())
        
        print(f"âœ… Tabla resumen generada: {output_file}")
    else:
        print("âŒ No se encontraron datos para resumen")

if __name__ == "__main__":
    if len(sys.argv) < 4:
        print("Uso: python generate_csv_data.py <baseline_dir> <perturbed_dir> <output_dir>")
        sys.exit(1)
    
    baseline_dir = sys.argv[1]
    perturbed_dir = sys.argv[2]
    output_dir = sys.argv[3]
    
    # Generar CSVs
    generate_comparison_csv(
        baseline_dir, 
        perturbed_dir,
        f"{output_dir}/datos_completos.csv"
    )
    
    generate_summary_table(
        baseline_dir,
        perturbed_dir,
        f"{output_dir}/tabla_resumen.csv"
    )
    
    print("\nâœ… Todos los CSVs generados correctamente")
EOFPYTHON

# Ejecutar generaciÃ³n de CSVs
python "${REPORTS_DIR}/generate_csv_data.py" \
    "$BASELINE_DIR" \
    "$PERTURBED_DIR" \
    "$REPORTS_DIR"

log_success "CSVs generados"

# ============================================================================
# FASE 5: REPORTE FINAL CONSOLIDADO
# ============================================================================

log_section "FASE 5: GENERACIÃ“N DE REPORTE CONSOLIDADO"

FINAL_REPORT="${REPORTS_DIR}/REPORTE_FINAL_TESIS.md"

log_progress "Generando reporte final consolidado..."

cat > "$FINAL_REPORT" << EOF
# ğŸ“Š REPORTE FINAL DE EVALUACIÃ“N - TESIS

**Fecha de generaciÃ³n**: $(date '+%Y-%m-%d %H:%M:%S')  
**Directorio de resultados**: $RESULTS_BASE

---

## ğŸ“‹ ConfiguraciÃ³n de la EvaluaciÃ³n

- **Arquitecturas evaluadas**: ${ARCHITECTURES[*]}
- **Proveedor LLM**: $PROVIDER
- **Modelo**: $MODEL
- **Suite de tareas**: $TASK_SUITE
- **Contextos por arquitectura**: $NUM_CONTEXTS
- **MÃ¡ximo de iteraciones**: $MAX_ITERATIONS

---

## ğŸ¯ Estructura de Resultados

\`\`\`
$RESULTS_BASE/
â”œâ”€â”€ baseline/              # Resultados sin perturbaciones
â”‚   â”œâ”€â”€ react_context1.json
â”‚   â”œâ”€â”€ react_context2.json
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ plan-then-act_context1.json
â”‚   â”œâ”€â”€ ...
â”‚
â”œâ”€â”€ perturbed/             # Resultados con perturbaciones
â”‚   â”œâ”€â”€ react_context1.json
â”‚   â”œâ”€â”€ ...
â”‚
â””â”€â”€ reports/               # AnÃ¡lisis y reportes
    â”œâ”€â”€ robustez_react_baseline.txt
    â”œâ”€â”€ robustez_react_perturbed.txt
    â”œâ”€â”€ ...
    â”œâ”€â”€ datos_completos.csv        # â† PARA GRÃFICOS
    â”œâ”€â”€ tabla_resumen.csv          # â† PARA TABLAS
    â””â”€â”€ REPORTE_FINAL_TESIS.md     # â† ESTE ARCHIVO
\`\`\`

---

## ğŸ“Š Archivos Clave para la Tesis

### 1. Datos Completos (para grÃ¡ficos)
**Archivo**: \`reports/datos_completos.csv\`

Contiene todas las mÃ©tricas individuales de cada contexto. Usar para:
- GrÃ¡ficos de barras (tasa de Ã©xito por arquitectura)
- GrÃ¡ficos de dispersiÃ³n (tiempo vs Ã©xito)
- Box plots (distribuciÃ³n de mÃ©tricas)

**Columnas**:
- \`architecture\`: Nombre de la arquitectura
- \`condition\`: "Baseline" o "Perturbado"
- \`context\`: NÃºmero de contexto (1-$NUM_CONTEXTS)
- \`success_rate\`: Tasa de Ã©xito (%)
- \`avg_time\`: Tiempo promedio (segundos)
- \`avg_steps\`: Pasos promedio
- \`avg_tokens\`: Tokens promedio

### 2. Tabla Resumen (para tablas en LaTeX)
**Archivo**: \`reports/tabla_resumen.csv\`

Contiene estadÃ­sticas agregadas (media Â± desv. estÃ¡ndar). Usar para:
- Tabla comparativa principal de la tesis
- AnÃ¡lisis de robustez (desviaciÃ³n estÃ¡ndar)

**Columnas**:
- \`architecture\`: Nombre de la arquitectura
- \`condition\`: "Baseline" o "Perturbado"
- \`success_mean\`: Media de tasa de Ã©xito
- \`success_std\`: DesviaciÃ³n estÃ¡ndar de tasa de Ã©xito
- \`time_mean\`: Media de tiempo
- \`time_std\`: DesviaciÃ³n estÃ¡ndar de tiempo
- \`steps_mean\`: Media de pasos
- \`steps_std\`: DesviaciÃ³n estÃ¡ndar de pasos
- \`tokens_mean\`: Media de tokens
- \`tokens_std\`: DesviaciÃ³n estÃ¡ndar de tokens

### 3. Reportes de Robustez (interpretaciÃ³n)
**Archivos**: \`reports/robustez_*_baseline.txt\` y \`reports/robustez_*_perturbed.txt\`

Contienen anÃ¡lisis detallado de robustez con:
- Coeficiente de variaciÃ³n (CV)
- InterpretaciÃ³n de consistencia
- Rating de robustez

---

## ğŸ“ˆ CÃ³mo Usar los Datos en la Tesis

### Para GrÃ¡ficos (Python/Matplotlib o R)

\`\`\`python
import pandas as pd
import matplotlib.pyplot as plt

# Cargar datos
df = pd.read_csv('reports/datos_completos.csv')

# GrÃ¡fico de barras: Tasa de Ã©xito por arquitectura
baseline = df[df['condition'] == 'Baseline']
plt.figure(figsize=(10, 6))
baseline.groupby('architecture')['success_rate'].mean().plot(kind='bar')
plt.title('Tasa de Ã‰xito por Arquitectura')
plt.ylabel('Tasa de Ã‰xito (%)')
plt.xlabel('Arquitectura')
plt.tight_layout()
plt.savefig('success_rate_comparison.png', dpi=300)
\`\`\`

### Para Tablas LaTeX

\`\`\`python
import pandas as pd

# Cargar resumen
df = pd.read_csv('reports/tabla_resumen.csv')

# Filtrar baseline
baseline = df[df['condition'] == 'Baseline']

# Generar LaTeX
print(baseline[['architecture', 'success_mean', 'success_std', 
                'time_mean', 'time_std']].to_latex(index=False))
\`\`\`

O manualmente:

\`\`\`latex
\\begin{table}[h]
\\centering
\\caption{ComparaciÃ³n de Arquitecturas Agentivas}
\\begin{tabular}{lcccc}
\\toprule
Arquitectura & Ã‰xito (\\%) & Tiempo (s) & Pasos & Tokens \\\\
\\midrule
ReAct        & 95.0 Â± 5.2 & 10.2 Â± 1.5 & 3.2 Â± 0.8 & 14748 Â± 2341 \\\\
Plan-Then-Act& 92.0 Â± 8.1 & 12.5 Â± 2.3 & 4.1 Â± 1.2 & 16523 Â± 3102 \\\\
Reference    & 97.0 Â± 3.2 & 11.8 Â± 1.2 & 3.8 Â± 0.6 & 15987 Â± 1876 \\\\
Reflexion    & 90.0 Â± 12.5 & 15.3 Â± 4.1 & 5.2 Â± 2.1 & 18234 Â± 4567 \\\\
\\bottomrule
\\end{tabular}
\\end{table}
\`\`\`

---

## ğŸ” AnÃ¡lisis de Robustez

Ver reportes individuales en:
EOF

# Agregar lista de reportes de robustez
for arch in "${ARCHITECTURES[@]}"; do
    echo "- \`reports/robustez_${arch}_baseline.txt\`" >> "$FINAL_REPORT"
    echo "- \`reports/robustez_${arch}_perturbed.txt\`" >> "$FINAL_REPORT"
done

cat >> "$FINAL_REPORT" << EOF

---

## âœ… Checklist para la Tesis

### SecciÃ³n de Resultados
- [ ] Tabla comparativa principal (usar \`tabla_resumen.csv\`)
- [ ] GrÃ¡fico de tasa de Ã©xito (usar \`datos_completos.csv\`)
- [ ] GrÃ¡fico de tiempo de ejecuciÃ³n
- [ ] GrÃ¡fico de consumo de tokens
- [ ] AnÃ¡lisis de robustez (usar reportes de robustez)

### SecciÃ³n de DiscusiÃ³n
- [ ] Comparar con baseline (con vs sin perturbaciones)
- [ ] Interpretar coeficientes de variaciÃ³n
- [ ] Discutir trade-offs (Ã©xito vs tiempo vs costo)
- [ ] Identificar arquitectura Ã³ptima por escenario

### SecciÃ³n de Conclusiones
- [ ] Resumir hallazgos principales
- [ ] Recomendaciones de selecciÃ³n arquitectÃ³nica
- [ ] Limitaciones del estudio
- [ ] Trabajo futuro

---

## ğŸ“ Soporte

Para regenerar grÃ¡ficos o anÃ¡lisis adicionales:
\`\`\`bash
# Regenerar CSVs
python reports/generate_csv_data.py baseline/ perturbed/ reports/

# Regenerar anÃ¡lisis de robustez
python analyze_robustness.py baseline/react_*.json > reports/robustez_react_nuevo.txt
\`\`\`

---

**Generado automÃ¡ticamente por el sistema de evaluaciÃ³n**
EOF

log_success "Reporte final generado: $FINAL_REPORT"

# ============================================================================
# RESUMEN FINAL
# ============================================================================

log_section "âœ… EVALUACIÃ“N COMPLETA FINALIZADA"

echo -e "${GREEN}"
cat << "EOF"
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘                         âœ… EVALUACIÃ“N COMPLETADA                             â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EOF
echo -e "${NC}"

log_success "Directorio de resultados: $RESULTS_BASE"
echo ""
log_info "ğŸ“Š Archivos clave generados:"
echo "   â€¢ Datos completos: $REPORTS_DIR/datos_completos.csv"
echo "   â€¢ Tabla resumen: $REPORTS_DIR/tabla_resumen.csv"
echo "   â€¢ Reporte final: $FINAL_REPORT"
echo ""
log_info "ğŸ“ PrÃ³ximos pasos:"
echo "   1. Revisar el reporte final: cat $FINAL_REPORT"
echo "   2. Generar grÃ¡ficos usando datos_completos.csv"
echo "   3. Incluir tabla_resumen.csv en tu tesis LaTeX"
echo ""
log_success "Â¡Todo listo para escribir la secciÃ³n de resultados! ğŸ‰"
echo ""

# Mostrar estadÃ­sticas finales
log_info "ğŸ“ˆ EstadÃ­sticas de ejecuciÃ³n:"
TOTAL_BENCHMARKS=$((${#ARCHITECTURES[@]} * $NUM_CONTEXTS * 2))
echo "   â€¢ Total de benchmarks ejecutados: $TOTAL_BENCHMARKS"
echo "   â€¢ Arquitecturas evaluadas: ${#ARCHITECTURES[@]}"
echo "   â€¢ Contextos por arquitectura: $NUM_CONTEXTS"
echo "   â€¢ Condiciones evaluadas: 2 (Baseline + Perturbaciones)"
echo ""

exit 0
